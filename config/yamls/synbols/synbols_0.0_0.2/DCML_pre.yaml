!!python/object:argparse.Namespace
dataset: synbols
n_shots: 5
n_shots_test: 15
m_tr: 20 #n_shots + n_shots_test, pretrain, same sample complexity as MAML. validation is used for evaluation not update parameters
m_va: 15
n_ways: 4
deeper: 0
hidden_size: 64
model_name: DCML
model_name_impv: DCML_pre
method: DMOGD
n_pretrain_epochs: 1000
n_pretrain_batches: 100
patience: 10
base_algo: SGD
meta_algo: OGD
# pretrain_model: models/omniglot_dmogd.model
#===========  adjust =========
pretrain_batch_size: 16 #task batch size
# K: 4 # inner epoch, steps=K*n_shots(m_tr for trainning)*n_ways/inner_batch_size
inner_batch_size: 80
# meta_lr: 0.25
# step_size: 0.01 #base_lr
#============ back up ==========
# pretrain_batch_size: 5 #task batch size
# K: 1 # inner epoch, steps=K*n_shots(m_tr for trainning)*n_ways/inner_batch_size
# inner_batch_size: 20
# meta_lr: 0.2
# step_size: 0.001 #base_lr
#===============================
# pretrain_batch_size: 25 #task batch size
# K: 1 # inner epoch, steps=K*n_shots(m_tr for trainning)*n_ways/inner_batch_size
# inner_batch_size: 200
# meta_lr: 0.2
# step_size: 0.1 #base_lr
#===============================
# pretrain_batch_size: 25 #task batch size
# K: 4 # inner epoch, steps=K*n_shots(m_tr for trainning)*n_ways/inner_batch_size
# inner_batch_size: 25
# meta_lr: 0.25
# step_size: 0.03 #base_lr
