!!python/object:argparse.Namespace
dataset: omniglot
n_shots: 5
n_ways: 10
timesteps: 10000
deeper: 0
hidden_size: 64
prob_statio: 0.0
model_name: fine_tuning
model_name_impv: fine_tuning
n_pretrain_epochs: 1000
patience: 20
pretrain_batch_size: 4
meta_lr: 0.001
num_steps: 1
step_size: 0.05
first_order: 0
learn_step_size: false
per_param_step_size: false
cl_accumulate: false
cl_strategy: always_retrain
cl_strategy_thres: 0.0
cl_tbd_thres: -1.0
mean_eta: 0.001
std_init: 0.01
l1_reg: 0.0
masks_init: 0.5
prob_env_switch: 0.2
pretrain_model: models/omniglot_maml.model
